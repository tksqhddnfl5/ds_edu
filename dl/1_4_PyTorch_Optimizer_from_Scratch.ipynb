{"cells":[{"cell_type":"markdown","metadata":{"id":"LegVBbqCahhn"},"source":["# PyTorch Optimizer from Scratch\n","\n","So far, we used optimizers pre-defined in ```torch.optim```, such as SGD, as below:\n","\n","```\n","import torch.optim as optim\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","```\n","\n","In this tutorial, we will take a deeper look into how PyTorch optimizer works, and implement a few optimization algorithms from scratch.\n","\n","(This tutorial is based on and modified from [this repository](https://github.com/bentrevett/a-tour-of-pytorch-optimizers/blob/main/a-tour-of-pytorch-optimizers.ipynb))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RwTbxA_rcfnY"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import RandomSampler\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","# https://pytorch.org/vision/stable/datasets.html\n","train_set = torchvision.datasets.MNIST(\n","    'data', train=True, transform=transforms.ToTensor(), download=True)\n","test_set = torchvision.datasets.MNIST(\n","    'data', train=False, transform=transforms.ToTensor(), download=True)\n","\n","# This sampler will run for 5k training steps\n","# https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler\n","sampler = RandomSampler(train_set,\n","                        replacement=True,  # 복원 추출\n","                        num_samples=100 * 5000)  # batch_size x training_steps\n","\n","# Use the sampler to create a data loader\n","train_loader = DataLoader(\n","    train_set, batch_size=100, sampler=sampler, num_workers=4)\n","\n","# Test loader runs for 1 epoch\n","test_loader = DataLoader(\n","    test_set, batch_size=200, num_workers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-AycM_tc5rS"},"outputs":[],"source":["\n","# define model\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.layer1 = nn.Linear(1 * 28 * 28, 256)  # MNIST image size\n","        self.layer2 = nn.Linear(256, 256)\n","        self.layer3 = nn.Linear(256, 128)\n","        self.layer4 = nn.Linear(128, 10)  # MNIST has 10 classes\n","\n","    def init_params(self):\n","        for n, p in self.named_parameters():\n","            if 'weight' in n:\n","                nn.init.kaiming_normal_(p, nonlinearity='relu')\n","            elif 'bias' in n:\n","                nn.init.constant_(p, 0)\n","\n","    def forward(self, x):\n","        # x: (B, 1, 28, 28)\n","        x = x.view(x.shape[0], -1)  # flatten, (B, 1*28*28)\n","        h1 = F.relu(self.layer1(x)) # (B, 256)\n","        h2 = F.relu(self.layer2(h1)) # (B, 256)\n","        h3 = F.relu(self.layer3(h2))  # (B, 128)\n","        return self.layer4(h3) # (B, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYOIUHIldRAp"},"outputs":[],"source":["# define training\n","\n","def train(dataloader, model, optimizer, criterion, device):\n","\n","    model.init_params()\n","    losses = []\n","\n","    for images, labels in tqdm(dataloader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        predictions = model(images)\n","        loss = criterion(predictions, labels)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss.item())\n","\n","    return losses\n","\n","@torch.no_grad()\n","def evaluate(dataloader, model, device):\n","    correct = 0\n","    total = 0\n","    for images, labels in tqdm(dataloader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        predictions = model(images)\n","        correct += (predictions.argmax(dim=1) == labels).sum()\n","        total += len(labels)\n","    return (correct / total).item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wuANQeyJdybk"},"outputs":[],"source":["# helper functions for plotting losses\n","def plot_loss(loss, title=None, ymin=0, ymax=None, figsize=(15,5)):\n","    \"\"\"Plots the loss from a single experiment.\"\"\"\n","\n","    fig, ax = plt.subplots(figsize=figsize)\n","    ax.plot(loss)\n","    ax.set_title(title)\n","    ax.set_ylabel('Loss')\n","    ax.set_xlabel('Update Steps')\n","    ax.set_ylim(ymin=ymin, ymax=ymax)\n","    ax.grid()\n","\n","def plot_losses(losses, labels, title=None, ymin=0, ymax=None, figsize=(15,5)):\n","    \"\"\"Plots the losses from multiple experiments.\"\"\"\n","\n","    fig, ax = plt.subplots(figsize=figsize)\n","    for loss, label in zip(losses, labels):\n","        ax.plot(loss, label=label)\n","    ax.set_title(title)\n","    ax.set_ylabel('Loss')\n","    ax.set_xlabel('Update Steps')\n","    ax.set_ylim(ymin=ymin, ymax=ymax)\n","    ax.grid()\n","    ax.legend(loc='upper right')\n"]},{"cell_type":"markdown","metadata":{"id":"wb3LebKdelBk"},"source":["Inside the ```train``` function, optimizer is used twice: ```optimizer.zero_grad()``` and ```optimizer.step()```."]},{"cell_type":"markdown","metadata":{"id":"1cvmJ7E8ejAF"},"source":["Now let's implement our first optimizer!\n","\n","## Optimizer 1: Stochastic Gradient Descent (SGD)\n","\n","Stochastic gradient descent is the simplest optimization algorithm, so it's a good place to start. We take our current model parameters $\\theta_t$ and subtract the gradient of those parameters, $\\nabla_\\theta J(\\theta_t)$, multiplied by the \"learning rate\", $\\eta$.\n","\n","The SGD algorithm is:\n","\n","$$\\theta_{t+1} = \\theta_t - \\eta \\cdot \\nabla_\\theta J(\\theta_t)$$\n","\n","However, we don't just have one set of parameters, $\\theta$, we have multiple parameters: the weights of layer 1, the biases of layer 1, the weights of layer 2, the biases of layer 2, etc. So we'll subscript the parameters with $i$:\n","\n","$$\\theta_{t+1,i} = \\theta_{t,i} - \\eta \\cdot \\nabla_\\theta J(\\theta_{t,i})$$\n","\n","We subtract because we want to descend the gradient and move towards a lower loss value. Addition would ascend the gradient, hence it's called gradient ascent.\n","\n","### Implementation\n","\n","All optimizers need a way of keeping track of the parameters they're supposed to be updating (`model_params`) and a learning rate (`lr`). SGD in PyTorch doesn't have a default learning rate but `1e-3` is a common default learning rate value for other optimizers, so we use it here. All optimizers need a `zero_grad` function in order to remove the gradients calculated from the last update step, and a `step` function to perform a parameter update.\n","\n","Note that any PyTorch method with a trailing underscore, e.g., `.sub_`, means the operation is in-place. This means our `step` function is updating each `param`, a tensor of parameters, in-place. These in-place operations are usually significantly faster than non in-place operations. It is also necessary in implementing PyTorch optimizer, **especially in updating the parameter value**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12noiS-te9Tu"},"outputs":[],"source":["class SGD:\n","    def __init__(self, model_params, lr=1e-3):\n","        self.model_params = list(model_params)\n","        self.lr = lr\n","\n","    def zero_grad(self):\n","        for param in self.model_params:\n","            param.grad = None\n","\n","    @torch.no_grad()\n","    def step(self):\n","        for param in self.model_params:\n","            # TODO\n","            # Hint: gradient is saved in param.grad\n","            # Hint: use in-place operation param.sub_(...)\n","            ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFCUg_lifkGz"},"outputs":[],"source":["\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","optimizer = SGD(model.parameters(), lr=1e-3)\n","sgd_loss = train(train_loader, model, optimizer, criterion, device)\n","sgd_acc = evaluate(test_loader, model, device)\n","\n","print()\n","print(f\"SGD test accuracy: {sgd_acc * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-30VyOgflch"},"outputs":[],"source":["plot_loss(sgd_loss, 'SGD with lr=1e-3')"]},{"cell_type":"markdown","metadata":{"id":"ca_sqVFvgQ2z"},"source":["\n","## Optimizer 2: SGD with Momentum\n","\n","One way to think of SGD is a ball rolling down a hill, where areas of high gradient are steep parts of the hill and areas of low gradient are very flat areas. Sometimes the global minima, the point with the lowest loss, is in the middle of a giant flat area. The problem is that because these flat areas have small gradients they also give small update steps which makes learning slow.\n","\n","What if we expanded on the \"ball rolling down a hill\" analogy? We'd want to add something to our optimizer that made it keep the \"momentum\" gained rolling down the steep hills whilst it's going across the flat areas.\n","\n","Well hey, that's exact what SGD with momentum does! Our parameter update is now calculated using a velocity, $v$, which depends on the current gradient multiplied by the learning rate plus the previous velocity multiplied by the momentum $\\gamma$.\n","\n","\\begin{align*}\n","    m_{t,i} &= \\gamma \\cdot m_{t-1,i} + \\nabla_\\theta J(\\theta_{t,i})\\\\\n","    \\theta_{t+1,i} &= \\theta_{t,i} - \\eta \\cdot m_{t,i}\\\\\n","\\end{align*}\n","\n","Note that the velocity `v` is a list of tensors (initialized as zero) corresponding to the model parameters, so we are storing the velocity of every single parameter in our model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UI8K8YuDfqpE"},"outputs":[],"source":["class SGDMomentum:\n","    def __init__(self, model_params, lr=1e-3, momentum=0.9):\n","        self.model_params = list(model_params)\n","        self.lr = lr\n","        self.momentum = momentum  # gamma\n","        self.m = {p: torch.zeros_like(p) for p in self.model_params}\n","\n","    def zero_grad(self):\n","        for param in self.model_params:\n","            param.grad = None\n","\n","    @torch.no_grad()\n","    def step(self):\n","        for param in self.model_params:\n","            # TODO\n","            # Hint: m corresponding to param can be accessed via self.m[param]\n","            ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwkG471gg4MY"},"outputs":[],"source":["\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","optimizer = SGDMomentum(model.parameters(), lr=1e-3)\n","sgd_momentum_loss = train(train_loader, model, optimizer, criterion, device)\n","\n","sgd_momentum_acc = evaluate(test_loader, model, device)\n","\n","print()\n","print(f\"SGDMomentum test accuracy: {sgd_momentum_acc * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z4JMu04fhBoU"},"outputs":[],"source":["plot_loss(sgd_momentum_loss, 'SGDMomentum with lr=1e-3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAx2t6jhhhD4"},"outputs":[],"source":["# Comparing SGD vs SGDMomentum\n","\n","losses = [sgd_loss, sgd_momentum_loss]\n","labels = ['sgd', 'sgd_momentum']\n","\n","plot_losses(losses, labels, 'SGD vs SGDMomentum')"]},{"cell_type":"markdown","metadata":{"id":"p1FO1SH1Z8eI"},"source":["\n","## Optimizer 3: RMSProp\n","\n","RMSProp solves the downside of AdaGrad that the accumulation of squared gradients from the beginning can cause an excessive decrease in the learning rate.\n","\n","The solution suggested by RMSProp is to use the exponentially decaying average of sqaured gradient to discard history from the extreme past.\n","\n","$$\\theta_{t+1, i} = \\theta_{t, i} - \\frac{\\eta}{\\sqrt{v_{t,i}} + \\epsilon} \\cdot g_{t,i}$$\n","\n","where:\n","\n","\\begin{align*}\n","    g_{t,i} &= \\nabla_\\theta J(\\theta_{t,i}) \\\\\n","    v_{t,i} &= \\rho v_{t-1,i} + (1-\\rho)g_{t,i}^2 \\\\\n","\\end{align*}\n","\n","with $v$ initialized to zero.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVS8BuO-cEPd"},"outputs":[],"source":["class RMSProp:\n","    def __init__(self, model_params, lr=1e-2, rho=0.999, eps=1e-8):\n","        self.model_params = list(model_params)\n","        self.lr = lr\n","        self.rho = rho\n","        self.eps = eps\n","        # TODO\n","        self.v = ...\n","\n","    def zero_grad(self):\n","        for param in self.model_params:\n","            param.grad = None\n","\n","    @torch.no_grad()\n","    def step(self):\n","        for param in self.model_params:\n","            # TODO\n","            ...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSjusc3dceyN"},"outputs":[],"source":["\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","optimizer = RMSProp(model.parameters(), lr=1e-2)\n","rmsprop_loss = train(train_loader, model, optimizer, criterion, device)\n","\n","rmsprop_acc = evaluate(test_loader, model, device)\n","\n","print()\n","print(f\"RMSProp test accuracy: {rmsprop_acc * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8ob5Hz9cksB"},"outputs":[],"source":["plot_loss(rmsprop_loss, 'RMSProp with lr=1e-2, rho=0.999, eps=1e-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xx-vG2Xhd_zj"},"outputs":[],"source":["plot_loss(rmsprop_loss, 'RMSProp with lr=1e-2, rho=0.999, eps=1e-8', ymax=3.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lANJPR4cpc-"},"outputs":[],"source":["# Comparing SGD vs SGDMomentum vs Adam\n","\n","losses = [sgd_loss, sgd_momentum_loss, rmsprop_loss]\n","labels = ['sgd', 'sgd_momentum', 'rmsprop']\n","\n","plot_losses(losses, labels, 'SGD vs SGDMomentum vs RMSProp', ymax=3.0)"]},{"cell_type":"markdown","metadata":{"id":"M2RFq4f1lRor"},"source":["\n","## Optimizer 4: Adam\n","\n","Adam uses RMSprop's idea of annealing the step size over time by using an exponential moving average to avoid saturation, and also utilize the idea of momentum.\n","\n","Adam has an exponential moving average of the gradients, like the momentum term that can be added to SGD, and an exponential moving average of squared gradients, like RMSprop.\n","\n","$$\\theta_{t+1, i} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_{t,i}}{\\sqrt{\\hat{v}_{t,i}}+\\epsilon}$$\n","\n","where:\n","\n","\\begin{align*}\n","    m_{t,i} &= \\beta_1 m_{t-1,i} + (1-\\beta_1)g_{t,i} \\\\\n","    v_{t,i} &= \\beta_2 v_{t-1,i} + (1-\\beta_2)g_{t,i}^2 \\\\\n","    \\hat{m}_{t,i} &= \\frac{m_{t,i}}{1-\\beta_1^t} \\\\\n","    \\hat{v}_{t,i} &= \\frac{v_{t,i}}{1-\\beta_2^t}\n","\\end{align*}\n","\n","with $m$ and $v$ initialized to zero.\n","\n","RMSProp and Momentum have problem that as $m$ and $v$ are initialized to zero and $\\beta_1$ and $\\beta_2$ are initialized close to one the $m$ and $v$ values calculated on the first few update steps are \"biased\" towards very small values.\n","(In RMSProp, this problem leads to spike in loss)\n","\n","Adam solves these problems by using \"bias corrected\" values of $m$ and $v$, which are $\\hat{m}$ and $\\hat{v}$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5Cprq_YkWoL"},"outputs":[],"source":["class Adam:\n","    def __init__(self, model_params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8):\n","        self.model_params = list(model_params)\n","        self.lr = lr\n","        self.beta_1, self.beta_2 = betas\n","        self.eps = eps\n","        self.n_steps = 0\n","        # TODO\n","        self.m = ...\n","        self.v = ...\n","\n","    def zero_grad(self):\n","        for param in self.model_params:\n","            param.grad = None\n","\n","    @torch.no_grad()\n","    def step(self):\n","        self.n_steps += 1\n","        for param in self.model_params:\n","            # TODO\n","            ...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7AJtI73nASp"},"outputs":[],"source":["\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","optimizer = Adam(model.parameters(), lr=1e-3)\n","adam_loss = train(train_loader, model, optimizer, criterion, device)\n","\n","adam_acc = evaluate(test_loader, model, device)\n","\n","print()\n","print(f\"Adam test accuracy: {adam_acc * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VoLYmmhznLdb"},"outputs":[],"source":["plot_loss(adam_loss, 'Adam with lr=1e-3, betas=(0.9, 0.999), eps=1e-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fNs4KConDN3"},"outputs":[],"source":["# Comparing SGD vs SGDMomentum vs Adam\n","\n","losses = [sgd_momentum_loss, rmsprop_loss, adam_loss]\n","labels = ['sgd_momentum', 'rmsprop', 'adam']\n","\n","plot_losses(losses, labels, 'SGDMomentum vs RMSProp vs Adam', ymax=3.0)"]},{"cell_type":"markdown","metadata":{"id":"SuuyO_9aoPil"},"source":["## Optimizer 5: Lion\n","\n","Unlike previous optimization algorithms which were hand-designed by human researchers, Lion was discovered via machine learning using the procedure called AutoML and evlutionary search.\n","Lion is known to perform better than AdamW (Adam with corrected weight decay) in large model training.\n","\n","Below is the optimization step of Lion (without weight decay)\n","\n","**Update model parameter**\n","\\begin{align*}\n","    c_{t,i} &= \\beta_1 m_{t-1,i} + (1 - \\beta_1)g_{t,i} \\\\\n","    \\theta_{t,i} &= \\theta_{t-1,i} - \\eta \\ \\text{sign}(c_{t,i}) \\\\\n","\\end{align*}\n","where $\\text{sign}$ is a function that returns 1 if input is larger than 0, 0 if equal to 0, and -1 otherwise. $m$ is initialized as zero.\n","\n","**Update $m_t$**\n","\\begin{align*}\n","    m_{t,i} &= \\beta_2 m_{t-1, i} + (1 - \\beta_2) g_{t, i}\n","\\end{align*}\n","\n","Reference: Chen et al., [*Symbolic Discovery of Optimization Algorithms*](https://arxiv.org/pdf/2302.06675) (2023)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XibRFd42nGgo"},"outputs":[],"source":["class Lion:\n","    def __init__(self, model_params, lr=1e-4, betas=(0.9, 0.99)):\n","        self.model_params = list(model_params)\n","        self.lr = lr\n","        self.beta_1, self.beta_2 = betas\n","        # TODO\n","        self.m = ...\n","\n","    def zero_grad(self):\n","        for param in self.model_params:\n","            param.grad = None\n","\n","    @torch.no_grad()\n","    def step(self):\n","        for param in self.model_params:\n","            # TODO\n","            ...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ys6REdH5r6Lk"},"outputs":[],"source":["\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","optimizer = Lion(model.parameters(), lr=1e-4)  # it is recommended to use smaller lr in Lion than in AdamW, which is Adam with decoupled weight decay\n","lion_loss = train(train_loader, model, optimizer, criterion, device)\n","\n","lion_acc = evaluate(test_loader, model, device)\n","\n","print()\n","print(f\"Lion test accuracy: {lion_acc * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7onQcwJSsFRv"},"outputs":[],"source":["plot_loss(lion_loss, 'Lion with lr=1e-4, betas=(0.9, 0.99)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uo1dUiYCsJgx"},"outputs":[],"source":["# Comparing Adam vs Lion\n","\n","losses = [adam_loss, lion_loss]\n","labels = ['adam', 'lion']\n","\n","plot_losses(losses, labels, 'Adam vs Lion')"]},{"cell_type":"markdown","metadata":{"id":"_6gl2dsrugrz"},"source":["## (Optional) Weight decay, param group, and inheriting torch.optim.Optimizer class\n","\n","The optimizers that we have implemented so far works well in our setting, but is not generalizable if we need\n","1. weight decay\n","2. different hyperparameter (e.g., learning rate, weight decay) for different parameter groups\n","\n","\n","Example of using param_group to apply different hyperparameter for different parameters (from [OpenCLIP implementation](https://github.com/mlfoundations/open_clip/blob/main/src/open_clip_train/main.py))\n","\n","```\n","exclude = lambda n, p: p.ndim < 2 or \"bn\" in n or \"ln\" in n or \"bias\" in n or 'logit_scale' in n\n","include = lambda n, p: not exclude(n, p)\n","\n","named_parameters = list(model.named_parameters())\n","gain_or_bias_params = [p for n, p in named_parameters if exclude(n, p) and p.requires_grad]\n","rest_params = [p for n, p in named_parameters if include(n, p) and p.requires_grad]\n","optimizer = optim.AdamW(\n","    [\n","        {\"params\": gain_or_bias_params, \"weight_decay\": 0.},\n","        {\"params\": rest_params, \"weight_decay\": args.wd},\n","    ],\n","    lr=args.lr,\n","    betas=(args.beta1, args.beta2),\n","    eps=args.eps,\n",")\n","```\n","\n","While the first limitation can be easily handled based on our code, the second limitation cannot. In this case, inheriting ```torch.optim.Optimizer``` class can be a solution.\n","\n","\n","Below is Lion optimizer (with weight decay) implemented by inheriting ```torch.optim.Optimizer``` class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-GwlU1l7sMwz"},"outputs":[],"source":["# copied and modified from https://github.com/jettify/pytorch-optimizer/blob/master/torch_optimizer/lion.py\n","\n","class CorrectLion(torch.optim.Optimizer):\n","\n","    def __init__(\n","        self,\n","        params,\n","        lr: float = 1e-4,\n","        betas = (0.9, 0.99),\n","        weight_decay: float = 0.0,\n","    ):\n","        if lr <= 0.0:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\n","                \"Invalid beta parameter at index 0: {}\".format(betas[0])\n","            )\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\n","                \"Invalid beta parameter at index 1: {}\".format(betas[1])\n","            )\n","        if weight_decay < 0:\n","            raise ValueError(\n","                \"Invalid weight_decay value: {}\".format(weight_decay)\n","            )\n","        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n","        super().__init__(params, defaults)\n","\n","    @torch.no_grad()\n","    def step(self, closure = None):\n","        r\"\"\"Performs a single optimization step.\n","\n","        Arguments:\n","            closure: A closure that reevaluates the model and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            with torch.enable_grad():\n","                loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group[\"params\"]:\n","                if p.grad is None:\n","                    continue\n","\n","                # Perform stepweight decay\n","                p.data.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n","\n","                grad = p.grad\n","                state = self.state[p]\n","                # State initialization\n","                if len(state) == 0:\n","                    # Exponential moving average of gradient values\n","                    state[\"exp_avg\"] = torch.zeros_like(p)\n","\n","                exp_avg = state[\"exp_avg\"]\n","                beta1, beta2 = group[\"betas\"]\n","\n","                # Weight update\n","                update = exp_avg * beta1 + grad * (1 - beta1)\n","                p.add_(torch.sign(update), alpha=-group[\"lr\"])\n","                # Decay the momentum running average coefficient\n","                exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)\n","\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pmSUadjv5or"},"outputs":[],"source":["\n","model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","optimizer = CorrectLion(model.parameters(), lr=1e-4, weight_decay=1.0)\n","correct_lion_loss = train(train_loader, model, optimizer, criterion, device)\n","\n","correct_lion_acc = evaluate(test_loader, model, device)\n","\n","print()\n","print(f\"CorrectLion test accuracy: {correct_lion_acc * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDi6X3YHwMg4"},"outputs":[],"source":["plot_loss(correct_lion_loss, 'CorrectLion with lr=1e-4, betas=(0.9, 0.99), wd=1.0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4QgopcywR_m"},"outputs":[],"source":["# Comparing Adam vs Lion vs CorrectLion\n","\n","losses = [adam_loss, lion_loss, correct_lion_loss]\n","labels = ['adam', 'lion', 'correct_lion']\n","\n","plot_losses(losses, labels, 'Adam vs Lion vs CorrectLion')"]},{"cell_type":"markdown","metadata":{"id":"s5gkYQVqzV4h"},"source":["If you are interested in optimizers not implemented in ```torch.optim``` (such as Lion, Lars, AdaFactor, ...), searching [pytorch-optimizer](https://github.com/jettify/pytorch-optimizer/tree/master) can be an option.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMpC14eifb_8"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}